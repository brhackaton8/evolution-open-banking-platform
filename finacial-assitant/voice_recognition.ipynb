{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dc9kSjkbMPi4",
        "outputId": "9d484578-809a-4e1a-ac4e-783f3c0cbd48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing: '.ipynb_checkpoints'\n",
            "\n",
            "Processing: 'ode'\n",
            "/content/dataset/ode/ode_8.wav: 1\n",
            "/content/dataset/ode/ode_3.wav: 1\n",
            "/content/dataset/ode/ode_5.wav: 1\n",
            "/content/dataset/ode/ode_6.wav: 1\n",
            "/content/dataset/ode/ode_1.wav: 1\n",
            "/content/dataset/ode/ode_4.wav: 1\n",
            "/content/dataset/ode/ode_2.wav: 1\n",
            "/content/dataset/ode/ode_12.wav: 1\n",
            "/content/dataset/ode/ode_11.wav: 1\n",
            "/content/dataset/ode/ode_10.wav: 1\n",
            "\n",
            "Processing: 'kochurmek'\n",
            "/content/dataset/kochurmek/kochur_5.wav: 2\n",
            "/content/dataset/kochurmek/kochur_7.wav: 2\n",
            "/content/dataset/kochurmek/kochur_4.wav: 2\n",
            "/content/dataset/kochurmek/kochur_1.wav: 2\n",
            "/content/dataset/kochurmek/kochur_6.wav: 2\n",
            "/content/dataset/kochurmek/kochur_2.wav: 2\n",
            "/content/dataset/kochurmek/kochur_3.wav: 2\n"
          ]
        }
      ],
      "source": [
        "import librosa\n",
        "import os\n",
        "import json\n",
        "\n",
        "DATASET_PATH = \"/content/dataset\"\n",
        "JSON_PATH = \"data.json\"\n",
        "SAMPLES_TO_CONSIDER = 22050 # 1 sec. of audio\n",
        "\n",
        "\n",
        "def preprocess_dataset(dataset_path, json_path, num_mfcc=13, n_fft=2048, hop_length=512):\n",
        "    \"\"\"Extracts MFCCs from music dataset and saves them into a json file.\n",
        "    :param dataset_path (str): Path to dataset\n",
        "    :param json_path (str): Path to json file used to save MFCCs\n",
        "    :param num_mfcc (int): Number of coefficients to extract\n",
        "    :param n_fft (int): Interval we consider to apply FFT. Measured in # of samples\n",
        "    :param hop_length (int): Sliding window for FFT. Measured in # of samples\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    # dictionary where we'll store mapping, labels, MFCCs and filenames\n",
        "    data = {\n",
        "        \"mapping\": [],\n",
        "        \"labels\": [],\n",
        "        \"MFCCs\": [],\n",
        "        \"files\": []\n",
        "    }\n",
        "\n",
        "    # loop through all sub-dirs\n",
        "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
        "\n",
        "        # ensure we're at sub-folder level\n",
        "        if dirpath is not dataset_path:\n",
        "\n",
        "            # save label (i.e., sub-folder name) in the mapping\n",
        "            label = dirpath.split(\"/\")[-1]\n",
        "            data[\"mapping\"].append(label)\n",
        "            print(\"\\nProcessing: '{}'\".format(label))\n",
        "\n",
        "            # process all audio files in sub-dir and store MFCCs\n",
        "            for f in filenames:\n",
        "                file_path = os.path.join(dirpath, f)\n",
        "\n",
        "                # load audio file and slice it to ensure length consistency among different files\n",
        "                signal, sample_rate = librosa.load(file_path)\n",
        "\n",
        "                # drop audio files with less than pre-decided number of samples\n",
        "                if len(signal) >= SAMPLES_TO_CONSIDER:\n",
        "\n",
        "                    # ensure consistency of the length of the signal\n",
        "                    signal = signal[:SAMPLES_TO_CONSIDER]\n",
        "\n",
        "                    # extract MFCCs\n",
        "                    MFCCs = librosa.feature.mfcc(signal, sample_rate, n_mfcc=num_mfcc, n_fft=n_fft,\n",
        "                                                 hop_length=hop_length)\n",
        "\n",
        "                    # store data for analysed track\n",
        "                    data[\"MFCCs\"].append(MFCCs.T.tolist())\n",
        "                    data[\"labels\"].append(i-1)\n",
        "                    data[\"files\"].append(file_path)\n",
        "                    print(\"{}: {}\".format(file_path, i-1))\n",
        "\n",
        "    # save data in json file\n",
        "    with open(json_path, \"w\") as fp:\n",
        "        json.dump(data, fp, indent=4)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    preprocess_dataset(DATASET_PATH, JSON_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "\n",
        "DATA_PATH = \"data.json\"\n",
        "SAVED_MODEL_PATH = \"model.h5\"\n",
        "EPOCHS = 40\n",
        "BATCH_SIZE = 32\n",
        "PATIENCE = 5\n",
        "LEARNING_RATE = 0.01\n",
        "\n",
        "\n",
        "def load_data(data_path):\n",
        "    \"\"\"Loads training dataset from json file.\n",
        "    :param data_path (str): Path to json file containing data\n",
        "    :return X (ndarray): Inputs\n",
        "    :return y (ndarray): Targets\n",
        "    \"\"\"\n",
        "    with open(data_path, \"r\") as fp:\n",
        "        data = json.load(fp)\n",
        "\n",
        "    X = np.array(data[\"MFCCs\"])\n",
        "    y = np.array(data[\"labels\"])\n",
        "    print(\"Training sets loaded!\")\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def prepare_dataset(data_path, test_size=0.2, validation_size=0.2):\n",
        "    \"\"\"Creates train, validation and test sets.\n",
        "    :param data_path (str): Path to json file containing data\n",
        "    :param test_size (flaot): Percentage of dataset used for testing\n",
        "    :param validation_size (float): Percentage of train set used for cross-validation\n",
        "    :return X_train (ndarray): Inputs for the train set\n",
        "    :return y_train (ndarray): Targets for the train set\n",
        "    :return X_validation (ndarray): Inputs for the validation set\n",
        "    :return y_validation (ndarray): Targets for the validation set\n",
        "    :return X_test (ndarray): Inputs for the test set\n",
        "    :return X_test (ndarray): Targets for the test set\n",
        "    \"\"\"\n",
        "\n",
        "    # load dataset\n",
        "    X, y = load_data(data_path)\n",
        "\n",
        "    # create train, validation, test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
        "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)\n",
        "\n",
        "    # add an axis to nd array\n",
        "    X_train = X_train[..., np.newaxis]\n",
        "    X_test = X_test[..., np.newaxis]\n",
        "    X_validation = X_validation[..., np.newaxis]\n",
        "\n",
        "    return X_train, y_train, X_validation, y_validation, X_test, y_test\n",
        "\n",
        "\n",
        "def build_model(input_shape, loss=\"sparse_categorical_crossentropy\", learning_rate=0.0001):\n",
        "    \"\"\"Build neural network using keras.\n",
        "    :param input_shape (tuple): Shape of array representing a sample train. E.g.: (44, 13, 1)\n",
        "    :param loss (str): Loss function to use\n",
        "    :param learning_rate (float):\n",
        "    :return model: TensorFlow model\n",
        "    \"\"\"\n",
        "\n",
        "    # build network architecture using convolutional layers\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "    # 1st conv layer\n",
        "    # model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=input_shape,\n",
        "    #                                  kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "    # model.add(tf.keras.layers.BatchNormalization())\n",
        "    # model.add(tf.keras.layers.MaxPooling2D((3, 3), strides=(2,2), padding='same'))\n",
        "\n",
        "    # 2nd conv layer\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu',input_shape=input_shape,\n",
        "                                     kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.MaxPooling2D((3, 3), strides=(2,2), padding='same'))\n",
        "\n",
        "    # # 3rd conv layer\n",
        "    # model.add(tf.keras.layers.Conv2D(32, (2, 2), activation='relu',\n",
        "    #                                  kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "    # model.add(tf.keras.layers.BatchNormalization())\n",
        "    # model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2,2), padding='same'))\n",
        "\n",
        "    # flatten output and feed into dense layer\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "    tf.keras.layers.Dropout(0.3)\n",
        "\n",
        "    # softmax output layer\n",
        "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    optimiser = tf.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    # compile model\n",
        "    model.compile(optimizer=optimiser,\n",
        "                  loss='binary_crossentropy' ,\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "    # print model parameters on console\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def train(model, epochs, batch_size, patience, X_train, y_train, X_validation, y_validation):\n",
        "    \"\"\"Trains model\n",
        "    :param epochs (int): Num training epochs\n",
        "    :param batch_size (int): Samples per batch\n",
        "    :param patience (int): Num epochs to wait before early stop, if there isn't an improvement on accuracy\n",
        "    :param X_train (ndarray): Inputs for the train set\n",
        "    :param y_train (ndarray): Targets for the train set\n",
        "    :param X_validation (ndarray): Inputs for the validation set\n",
        "    :param y_validation (ndarray): Targets for the validation set\n",
        "    :return history: Training history\n",
        "    \"\"\"\n",
        "\n",
        "    earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\", min_delta=0.001, patience=patience)\n",
        "\n",
        "    # train model\n",
        "    history = model.fit(X_train,\n",
        "                        y_train,\n",
        "                        epochs=epochs,\n",
        "                        batch_size=batch_size,\n",
        "                        validation_data=(X_validation, y_validation),\n",
        "                        callbacks=[earlystop_callback])\n",
        "    return history\n",
        "\n",
        "\n",
        "def plot_history(history):\n",
        "    \"\"\"Plots accuracy/loss for training/validation set as a function of the epochs\n",
        "    :param history: Training history of model\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    fig, axs = plt.subplots(2)\n",
        "\n",
        "    # create accuracy subplot\n",
        "    axs[0].plot(history.history[\"accuracy\"], label=\"accuracy\")\n",
        "    axs[0].plot(history.history['val_accuracy'], label=\"val_accuracy\")\n",
        "    axs[0].set_ylabel(\"Accuracy\")\n",
        "    axs[0].legend(loc=\"lower right\")\n",
        "    axs[0].set_title(\"Accuracy evaluation\")\n",
        "\n",
        "    # create loss subplot\n",
        "    axs[1].plot(history.history[\"loss\"], label=\"loss\")\n",
        "    axs[1].plot(history.history['val_loss'], label=\"val_loss\")\n",
        "    axs[1].set_xlabel(\"Epoch\")\n",
        "    axs[1].set_ylabel(\"Loss\")\n",
        "    axs[1].legend(loc=\"upper right\")\n",
        "    axs[1].set_title(\"Loss evaluation\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def main():\n",
        "    # generate train, validation and test sets\n",
        "    X_train, y_train, X_validation, y_validation, X_test, y_test = prepare_dataset(DATA_PATH)\n",
        "    print(X_train.shape)\n",
        "\n",
        "    # create network\n",
        "    input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
        "    model = build_model(input_shape, learning_rate=LEARNING_RATE)\n",
        "\n",
        "    # train network\n",
        "    history = train(model, EPOCHS, BATCH_SIZE, PATIENCE, X_train, y_train, X_validation, y_validation)\n",
        "\n",
        "    # plot accuracy/loss for training/validation set as a function of the epochs\n",
        "    plot_history(history)\n",
        "\n",
        "    # evaluate network on test set\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "    print(\"\\nTest loss: {}, test accuracy: {}\".format(test_loss, 100*test_acc))\n",
        "\n",
        "    # save model\n",
        "    model.save(SAVED_MODEL_PATH)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YpvfDXhcM2dc",
        "outputId": "5983e1cf-0099-4efa-d79c-5f196106dabf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training sets loaded!\n",
            "(10, 44, 13, 1)\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_19 (Conv2D)          (None, 42, 11, 32)        320       \n",
            "                                                                 \n",
            " batch_normalization_19 (Bat  (None, 42, 11, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 21, 6, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (None, 4032)              0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 64)                258112    \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 258,625\n",
            "Trainable params: 258,561\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n",
            "Epoch 1/40\n",
            "1/1 [==============================] - 1s 815ms/step - loss: -2.0968 - accuracy: 0.4000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 2/40\n",
            "1/1 [==============================] - 0s 44ms/step - loss: -127.7155 - accuracy: 0.4000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 3/40\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -275.3338 - accuracy: 0.4000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 4/40\n",
            "1/1 [==============================] - 0s 40ms/step - loss: -446.9561 - accuracy: 0.4000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 5/40\n",
            "1/1 [==============================] - 0s 46ms/step - loss: -644.7341 - accuracy: 0.4000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 6/40\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -875.4707 - accuracy: 0.4000 - val_loss: 0.0022 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step - loss: -1556.4717 - accuracy: 0.7500\n",
            "\n",
            "Test loss: -1556.4716796875, test accuracy: 75.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "SAVED_MODEL_PATH = \"model.h5\"\n",
        "SAMPLES_TO_CONSIDER = 22050\n",
        "\n",
        "class _Keyword_Spotting_Service:\n",
        "    \"\"\"Singleton class for keyword spotting inference with trained models.\n",
        "    :param model: Trained model\n",
        "    \"\"\"\n",
        "\n",
        "    model = None\n",
        "    _mapping = [\n",
        "        \"kochurmek\",\n",
        "        \"ode\",\n",
        "    ]\n",
        "    _instance = None\n",
        "\n",
        "\n",
        "    def predict(self, file_path):\n",
        "        \"\"\"\n",
        "        :param file_path (str): Path to audio file to predict\n",
        "        :return predicted_keyword (str): Keyword predicted by the model\n",
        "        \"\"\"\n",
        "\n",
        "        # extract MFCC\n",
        "        MFCCs = self.preprocess(file_path)\n",
        "\n",
        "        # we need a 4-dim array to feed to the model for prediction: (# samples, # time steps, # coefficients, 1)\n",
        "        MFCCs = MFCCs[np.newaxis, ..., np.newaxis]\n",
        "\n",
        "        # get the predicted label\n",
        "        predictions = self.model.predict(MFCCs)\n",
        "        predicted_index = np.argmax(predictions)\n",
        "        predicted_keyword = self._mapping[predicted_index]\n",
        "        return predicted_keyword\n",
        "\n",
        "\n",
        "    def preprocess(self, file_path, num_mfcc=13, n_fft=2048, hop_length=512):\n",
        "        \"\"\"Extract MFCCs from audio file.\n",
        "        :param file_path (str): Path of audio file\n",
        "        :param num_mfcc (int): # of coefficients to extract\n",
        "        :param n_fft (int): Interval we consider to apply STFT. Measured in # of samples\n",
        "        :param hop_length (int): Sliding window for STFT. Measured in # of samples\n",
        "        :return MFCCs (ndarray): 2-dim array with MFCC data of shape (# time steps, # coefficients)\n",
        "        \"\"\"\n",
        "\n",
        "        # load audio file\n",
        "        signal, sample_rate = librosa.load(file_path)\n",
        "\n",
        "        if len(signal) >= SAMPLES_TO_CONSIDER:\n",
        "            # ensure consistency of the length of the signal\n",
        "            signal = signal[:SAMPLES_TO_CONSIDER]\n",
        "\n",
        "            # extract MFCCs\n",
        "            MFCCs = librosa.feature.mfcc(signal, sample_rate, n_mfcc=num_mfcc, n_fft=n_fft,\n",
        "                                         hop_length=hop_length)\n",
        "        return MFCCs.T\n",
        "\n",
        "\n",
        "def Keyword_Spotting_Service():\n",
        "    \"\"\"Factory function for Keyword_Spotting_Service class.\n",
        "    :return _Keyword_Spotting_Service._instance (_Keyword_Spotting_Service):\n",
        "    \"\"\"\n",
        "\n",
        "    # ensure an instance is created only the first time the factory function is called\n",
        "    if _Keyword_Spotting_Service._instance is None:\n",
        "        _Keyword_Spotting_Service._instance = _Keyword_Spotting_Service()\n",
        "        _Keyword_Spotting_Service.model = tf.keras.models.load_model(SAVED_MODEL_PATH)\n",
        "    return _Keyword_Spotting_Service._instance\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # create 2 instances of the keyword spotting service\n",
        "    kss = Keyword_Spotting_Service()\n",
        "    kss1 = Keyword_Spotting_Service()\n",
        "\n",
        "    # check that different instances of the keyword spotting service point back to the same object (singleton)\n",
        "    assert kss is kss1\n",
        "\n",
        "    # make a prediction\n",
        "    keyword = kss.predict(\"/content/kochurme.test.wav\")\n",
        "    print(keyword)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du-2B42imPC-",
        "outputId": "403f6fb0-05eb-4fdc-d0f9-edab5d773e1d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f193eb60170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "kochurmek\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CDizmdxpwi1s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}